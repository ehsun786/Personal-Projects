{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import os \n",
    "import sys\n",
    "import h5py, os\n",
    "from functions import transforms as T\n",
    "from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list\n",
    "        self.acceleration = acceleration\n",
    "        self.center_fraction = center_fraction\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')\n",
    "        \n",
    "def show_single_slice(data, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    plt.imshow(data, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "        \n",
    "    return img_gt.squeeze(0), img_und.squeeze(0), rawdata_und.squeeze(0), masks.squeeze(0), norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "    \n",
    "        for fname in sorted(os.listdir(which_data_path)):\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path, fname)\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "            with h5py.File(subject_data_path, 'r') as data:\n",
    "                if i==0:\n",
    "                    k='kspace'\n",
    "                if i==1:\n",
    "                    k='kspace_4af'\n",
    "                num_slice = data[k].shape[0]\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "    \n",
    "    return data_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainData(number):\n",
    "    if (number==0):\n",
    "        return []\n",
    "    data_path_train = '/data/local/NC2019MRI/train'\n",
    "    data_path_val = '/data/local/NC2019MRI/test'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n",
    "\n",
    "    acc = 8\n",
    "    cen_fract = 0.04\n",
    "    seed = False # random masks for each slice \n",
    "    num_workers = 0 #12 # data loading is faster using a bigger number for num_workers. 0 means using one cpu to load data\n",
    "    \n",
    "    # create data loader for training set. It applies same to validation set as well\n",
    "    train_dataset = MRIDataset(data_list['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1, num_workers=num_workers) \n",
    "    data=[]\n",
    "    for iteration, sample in enumerate(train_loader):\n",
    "        \n",
    "        img_gt, img_und, rawdata_und, masks, norm = sample\n",
    "         \n",
    "        # stack different slices into a volume for visualisation\n",
    "        A = masks[...,0].squeeze()\n",
    "        B = torch.log(T.complex_abs(rawdata_und) + 1e-9).squeeze()\n",
    "        C = T.complex_abs(img_und).squeeze()\n",
    "        D = T.complex_abs(img_gt).squeeze()\n",
    "        all_imgs = torch.stack([A,B,C,D], dim=0)\n",
    "        data.append(all_imgs)\n",
    "\n",
    "        # from left to right: mask, masked kspace, undersampled image, ground truth\n",
    "        #show_slices(all_imgs, [0, 1, 2, 3], cmap='gray')\n",
    "        #plt.pause(1)\n",
    "\n",
    "        if iteration >= (number-1): \n",
    "            #print(\"Breaking\")\n",
    "            break  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaders():\n",
    "    data_path_train = '/data/local/NC2019MRI/train'\n",
    "    data_path_val = '/data/local/NC2019MRI/test'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n",
    "\n",
    "    acc = 8\n",
    "    cen_fract = 0.04\n",
    "    seed = False # random masks for each slice \n",
    "    num_workers = 0 #12 # data loading is faster using a bigger number for num_workers. 0 means using one cpu to load data\n",
    "    \n",
    "    # create data loader for training set. It applies same to validation set as well\n",
    "    train_dataset = MRIDataset(data_list['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1, num_workers=num_workers)     \n",
    "  \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.subsample import MaskFunc\n",
    "\n",
    "def apply4Mask(vk):\n",
    "    volume_kspace = T.to_tensor(vk)\n",
    "    mask_func0 = MaskFunc(center_fractions=[0.08], accelerations=[4])  # Create the mask function object\n",
    "    shape = np.array(volume_kspace.shape)\n",
    "    mask0 = mask_func0(shape, seed=0) # use seed here to exclude randomness  \n",
    "    masked_kspace0 = torch.where(mask0 == 0, torch.Tensor([0]), volume_kspace)\n",
    "    S_Num, Ny, Nx, _ = volume_kspace.shape\n",
    "    masks0 = mask0.repeat(S_Num, Ny, 1, 1).squeeze() # masks when AF=4\n",
    "    return masked_kspace0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def getRandomValData():\n",
    "    file_path = '/data/local/NC2019MRI/test/'\n",
    "    valData=np.asarray([])\n",
    "    num=random.randint(0,len(sorted(os.listdir(file_path)))-1)\n",
    "    fname=sorted(os.listdir(file_path))[num]\n",
    "    subject_path = os.path.join(file_path, fname)\n",
    "    with h5py.File(subject_path,  \"r\") as hf:\n",
    "        volume_kspace_4af = hf['kspace_4af'][()] \n",
    "        return volume_kspace_4af\n",
    "\n",
    "        \n",
    "def getRandomTrainData():\n",
    "    file_path = '/data/local/NC2019MRI/train/'\n",
    "    valData=np.asarray([])\n",
    "    num=random.randint(0,len(sorted(os.listdir(file_path)))-1)\n",
    "    fname=sorted(os.listdir(file_path))[num]\n",
    "    subject_path = os.path.join(file_path, fname)\n",
    "    with h5py.File(subject_path,  \"r\") as hf:\n",
    "        volume_kspace = hf['kspace'][()] \n",
    "        volume_kspace_4af=apply4Mask(volume_kspace)\n",
    "        volume_kspace_4af.requires_grad=True\n",
    "        volume_kspace2 = T.to_tensor(volume_kspace) \n",
    "        volume_kspace2.requires_grad=True\n",
    "        volume_image = T.ifft2(volume_kspace2) \n",
    "        #volume_image.requires_grad=True\n",
    "        volume_image_abs = T.complex_abs(volume_image)\n",
    "        return volume_kspace_4af ,volume_image\n",
    "            \n",
    "vd,ri=getRandomTrainData()\n",
    "num=random.randint(0,vd.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create loader with data, so that we can iterate over it\n",
    "DL = getLoaders() #torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscriminatorNet(\n",
       "  (l1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (l2): Sequential(\n",
       "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (l3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (l4): Sequential(\n",
       "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (l5): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (l6): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (l7): Sequential(\n",
       "    (0): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (l8): Sequential(\n",
       "    (0): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 1\n",
    "        n_out = 1\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_features, out_channels=16, kernel_size=4, stride=2, padding=1, bias = False)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace = True)\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2, padding=1, bias = False)\n",
    "        )\n",
    "        self.l4 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace = True)\n",
    "        )\n",
    "        self.l5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1, bias = False)\n",
    "        )\n",
    "        self.l6 = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, 4, 1, 0, bias = False)\n",
    "        )\n",
    "        self.l7 = nn.Sequential(\n",
    "            nn.AdaptiveMaxPool2d((1,1))\n",
    "        )\n",
    "        self.l8 = nn.Sequential(\n",
    "            nn.Sigmoid()\n",
    "        )       \n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Before l1\",x.shape)\n",
    "        x = self.l1(x) \n",
    "        #print(\"Before l2\",x.shape)\n",
    "        x = self.l2(x)\n",
    "        #print(\"Before l3\",x.shape)\n",
    "        x = self.l3(x)\n",
    "        #print(\"Before l4\",x.shape)\n",
    "        x = self.l4(x)\n",
    "        #print(\"Before l5\",x.shape)\n",
    "        x = self.l5(x)\n",
    "        #print(\"Before l6\",x.shape)\n",
    "        x = self.l6(x)\n",
    "        #print(\"Before l7\",x.shape)\n",
    "        x = self.l7(x)\n",
    "        #print(\"Before l8\",x.shape)\n",
    "        x = self.l8(x)\n",
    "        #print(\"Final gen_out\",x.shape)\n",
    "        return x\n",
    "discriminator = DiscriminatorNet()\n",
    "discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)     \n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "    \n",
    "generator = UNet(n_channels=1, n_classes=2)\n",
    "generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1).cuda())\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1).cuda())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim \n",
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    gtn=gt.detach().numpy()\n",
    "    predn=pred.detach().numpy()\n",
    "    \n",
    "    ssim_val= compare_ssim(gtn.transpose(1, 2, 0), predn.transpose(1, 2, 0), multichannel=True, data_range=gtn.max())\n",
    "    ssim_val_numpy=np.asarray([ssim_val])\n",
    "    ssim_val_tensor=torch.tensor(ssim_val_numpy,requires_grad=True)     \n",
    "    return ssim_val_tensor\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data.unsqueeze(0).unsqueeze(0))\n",
    "    error_real = loss(prediction_real.squeeze().squeeze().squeeze(), ones_target(1) )\n",
    "    error_real.backward(retain_graph=True)\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data.unsqueeze(0).unsqueeze(0))\n",
    "    error_fake = loss(prediction_fake, zeros_target(1))\n",
    "    error_fake.backward(retain_graph=True)\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error and predictions for real and fake inputs\n",
    "    return error_real + error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data, real_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    prediction = discriminator(fake_data.unsqueeze(0).unsqueeze(0))\n",
    "    error = loss(prediction, ones_target(1)) #changed from prediction\n",
    "    error.backward(retain_graph=True)\n",
    "    fake_data.cuda()\n",
    "    real_data.cuda()\n",
    "    optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_single_tensor_slice(t):\n",
    "    t=t.detach().cpu()\n",
    "    show_single_slice(t.squeeze(0), cmap='gray')\n",
    "    t.cuda()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 SSIM Ave 0.2895725973125222\n",
      "Epoch 1 SSIM Ave 0.27145744518930126\n",
      "Epoch 2 SSIM Ave 0.27868270756723945\n",
      "Epoch 3 SSIM Ave 0.31511837224590994\n",
      "Epoch 4 SSIM Ave 0.27523818622361634\n",
      "Epoch 5 SSIM Ave 0.19238518161438875\n",
      "Epoch 6 SSIM Ave 0.20907189833629464\n",
      "Epoch 7 SSIM Ave 0.2651034731048085\n",
      "Epoch 8 SSIM Ave 0.24516829526128167\n",
      "Epoch 9 SSIM Ave 0.25317174086296723\n"
     ]
    }
   ],
   "source": [
    "# Total number of epochs to train\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    ssim_error=[]\n",
    "    done=False\n",
    "    for iteration, sample  in enumerate(DL): \n",
    "        img_gt, img_und, rawdata_und, masks, norm = sample\n",
    "        \n",
    "        img_gt.requires_grad=True\n",
    "        img_und.requires_grad=True\n",
    "        rawdata_und.requires_grad=True\n",
    "        # stack different slices into a volume for visualisation\n",
    "        A = masks[...,0].squeeze()\n",
    "        B = torch.log(T.complex_abs(rawdata_und) + 1e-9).squeeze()\n",
    "        C = T.complex_abs(img_und).squeeze()\n",
    "        D = T.complex_abs(img_gt).squeeze()\n",
    "        all_imgs = torch.stack([A,B,C,D], dim=0)\n",
    "\n",
    "        \n",
    "        # 1. Train Discriminator\n",
    "        comp_img_gt = T.complex_abs(img_gt)   \n",
    "        fs=T.center_crop(comp_img_gt, [320, 320])\n",
    "        real_data = Variable(fs.squeeze(0),requires_grad=True).cuda()\n",
    "        \n",
    "        # Generate fake data and detach \n",
    "        fs = T.complex_abs(T.ifft2(rawdata_und)).squeeze() #640x372\n",
    "        fs=T.center_crop(fs, [320, 320])   #320x320\n",
    "        gen_input=Variable(fs.unsqueeze(0).unsqueeze(0),requires_grad=True).cuda() \n",
    "        fake_data_tensor = generator(gen_input)  #Output from gen,\n",
    "        fake_data_tensor=fake_data_tensor.squeeze().permute(1,2,0) \n",
    "        fake_data_img=T.complex_abs(fake_data_tensor)\n",
    "        \n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, real_data, fake_data_img)\n",
    "\n",
    "        \n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        \n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data_img, real_data)\n",
    "        \n",
    "        \n",
    "        # Display Progress every few batches\n",
    "        if (((iteration) % 100 == 0)):\n",
    "            test_gen_input, real_image=getRandomTrainData()            \n",
    "            num=random.randint(0,test_gen_input.shape[0]-1)\n",
    "            slice_of_test_data=test_gen_input[num]\n",
    "            \n",
    "           \n",
    "            fs = T.complex_abs(T.ifft2(test_gen_input[num].unsqueeze(0))).squeeze() #640x372\n",
    "            fs=T.center_crop(fs, [320, 320])   #320x320\n",
    "            test_gen_input=Variable(fs.unsqueeze(0).unsqueeze(0)).cuda() \n",
    "            \n",
    "            gen_out = generator(test_gen_input).detach()\n",
    "            \n",
    "            \n",
    "            fake_result=T.complex_abs(gen_out.squeeze().permute(1,2,0))\n",
    "            \n",
    "           \n",
    "            ssim_real=T.center_crop(T.complex_abs(real_image[num]), [320, 320]).detach().cuda()   \n",
    "            ssim_val=ssim(fake_result.unsqueeze(0).cpu(),ssim_real.unsqueeze(0).cpu())\n",
    "            #print(\"SSIM\",ssim_val.detach().numpy()[0])\n",
    "            ssim_error.append(ssim_val.detach().numpy()[0])\n",
    "            done=True\n",
    "    print(\"Epoch\",epoch,\"SSIM Ave\",np.mean(np.asarray(ssim_error)))\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
